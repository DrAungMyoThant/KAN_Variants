def train_and_evaluate_with_losses(model,
                                   train_loader,
                                   test_loader,
                                   epochs,
                                   lr,
                                   device,
                                   metrics_dict,
                                   n_classes):
    """
    A modified training/evaluation function that also returns
    epoch-by-epoch training & validation losses.
    """
    if metrics_dict['num_parameters'] is None:
        metrics_dict['num_parameters'] = sum(
            p.numel() for p in model.parameters() if p.requires_grad
        )

    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    best_accuracy = 0.0
    best_metrics  = None

    train_losses = []
    val_losses   = []

    for ep in range(epochs):
        # --------------------- TRAINING ---------------------
        model.train()
        total_loss = 0.0
        total_correct = 0

        for eeg_batch, eye_batch, labels_batch in train_loader:
            eeg_batch    = eeg_batch.to(device)
            eye_batch    = eye_batch.to(device)
            labels_batch = labels_batch.to(device)

            optimizer.zero_grad()
            outputs = model(eeg_batch, eye_batch)
            loss    = criterion(outputs, labels_batch)
            loss.backward()
            optimizer.step()

            total_loss    += loss.item() * labels_batch.size(0)
            _, predicted   = torch.max(outputs, dim=1)
            total_correct += (predicted == labels_batch).sum().item()

        epoch_train_loss = total_loss / len(train_loader.dataset)
        epoch_train_acc  = total_correct / len(train_loader.dataset)
        train_losses.append(epoch_train_loss)

        # ------------------- VALIDATION ---------------------
        model.eval()
        val_total_loss = 0.0
        val_correct    = 0
        all_labels     = []
        all_preds      = []
        all_probs      = []

        with torch.no_grad():
            for eeg_val, eye_val, labels_val in test_loader:
                eeg_val    = eeg_val.to(device)
                eye_val    = eye_val.to(device)
                labels_val = labels_val.to(device)

                outputs_val = model(eeg_val, eye_val)
                val_loss    = criterion(outputs_val, labels_val)
                val_total_loss += val_loss.item() * labels_val.size(0)

                _, val_pred   = torch.max(outputs_val, dim=1)
                val_correct  += (val_pred == labels_val).sum().item()

                all_labels.extend(labels_val.cpu().numpy())
                all_preds.extend(val_pred.cpu().numpy())
                probs = torch.softmax(outputs_val, dim=1)
                all_probs.extend(probs.cpu().numpy())

        epoch_val_loss = val_total_loss / len(test_loader.dataset)
        epoch_val_acc  = val_correct / len(test_loader.dataset)
        val_losses.append(epoch_val_loss)

        # Compute additional metrics
        f1_val   = f1_score(all_labels, all_preds, average='macro')
        prec_val = precision_score(all_labels, all_preds, average='macro')
        rec_val  = recall_score(all_labels, all_preds, average='macro')

        labels_bin = label_binarize(all_labels, classes=range(n_classes))
        try:
            auc_val = roc_auc_score(labels_bin, np.array(all_probs),
                                    average='macro', multi_class='ovr')
        except ValueError:
            auc_val = float('nan')

        cm = confusion_matrix(all_labels, all_preds)

        # Track best accuracy
        if epoch_val_acc > best_accuracy:
            best_accuracy = epoch_val_acc
            best_metrics  = {
                'accuracy':   best_accuracy,
                'precision':  prec_val,
                'recall':     rec_val,
                'f1':         f1_val,
                'auc':        auc_val,
                'confusion_matrix': cm
            }

        print(f"Epoch [{ep+1}/{epochs}] | "
              f"Train Loss: {epoch_train_loss:.4f} | "
              f"Val Loss: {epoch_val_loss:.4f} | "
              f"Train Acc: {epoch_train_acc:.4f} | "
              f"Val Acc: {epoch_val_acc:.4f} | "
              f"F1: {f1_val:.4f}")

    # Save best metrics in metrics_dict
    metrics_dict['accuracy'].append(best_metrics['accuracy'])
    metrics_dict['precision'].append(best_metrics['precision'])
    metrics_dict['recall'].append(best_metrics['recall'])
    metrics_dict['f1'].append(best_metrics['f1'])
    metrics_dict['auc'].append(best_metrics['auc'])
    metrics_dict['confusion_matrix'] += best_metrics['confusion_matrix']

    # Return the recorded loss curves
    return train_losses, val_losses

all_loss_curves = {
    #"MLP": {
    #    "train": [],
    #    "val": []
    #},
    "Wavelet KAN (dog)": {
        "train": [],
        "val": []
    },
    "Wavelet KAN (morlet)": {
        "train": [],
        "val": []
    },
    "Wavelet KAN (mexican_hat)": {
        "train": [],
        "val": []
    },
    "Wavelet KAN (meyer)": {
        "train": [],
        "val": []
    },
    #"Wavelet KAN (shannon)": {
    #    "train": [],
    #    "val": []
    #},

    # ...
    "Efficient KAN": {
        "train": [],
        "val": []
    },
    "Jacobi-KAN": {
        "train": [],
        "val": []
    },
    "Chebyshev-KAN": {
        "train": [],
        "val": []
    },
    "Fourier-KAN": {
        "train": [],
        "val": []
    },
    "Hermite-KAN": {
        "train": [],
        "val": []
    },
    "RBF-KAN": {
        "train": [],
        "val": []
    }
}
